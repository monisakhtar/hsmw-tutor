# ğŸ“ HSMW Tutor

A **NotebookLM-style Q&A system** for Hochschule Mittweida (HSMW) students. Upload lecture PDFs and ask questions in natural language â€” the system retrieves relevant passages and generates grounded answers using a local/remote LLM.

---

## ğŸ§  How It Works

```
PDF Upload â†’ Text Extraction â†’ Chunking â†’ Embeddings â†’ ChromaDB
                                                            â†“
Question â†’ Query Rewriting â†’ Retrieval â†’ LLM Generation â†’ Answer
                  â†‘                            â†“
                  â””â”€â”€â”€â”€ Self-Grading (retry if not grounded) â”€â”€â”€â”€â”˜
```

The system uses a **LangGraph agentic pipeline** with 4 nodes:

1. **Query Rewriting** â€” Rewrites the student's question for better retrieval
2. **Retrieval** â€” Fetches the top-k most relevant chunks from ChromaDB
3. **Answer Generation** â€” Generates a grounded answer using the LLM
4. **Self-Grading** â€” Checks if the answer is grounded in the retrieved docs; retries if not

---

## ğŸ› ï¸ Tech Stack

| Component | Technology |
|-----------|-----------|
| UI | Streamlit |
| LLM & Embeddings | Ollama (remote HSMW server) |
| Vector Store | ChromaDB |
| RAG Pipeline | LangChain + LangGraph |
| PDF Parsing | PyMuPDF (fitz) |
| Config Management | gin-config |
| Package Manager | uv |

---

## ğŸ“ Project Structure

```
hsmw-tutor/
â”œâ”€â”€ sicim/
â”‚   â””â”€â”€ config.gin          # Remote Ollama credentials (not committed to git)
â”œâ”€â”€ chroma_db/              # Persisted vector store
â”œâ”€â”€ app.py                  # Streamlit UI entry point
â”œâ”€â”€ config.py               # App settings & client initialization
â”œâ”€â”€ ingestion.py            # PDF â†’ chunks â†’ ChromaDB pipeline
â”œâ”€â”€ retrieval.py            # ChromaDB retriever
â”œâ”€â”€ chain.py                # LangGraph agentic RAG pipeline
â”œâ”€â”€ pyproject.toml          # uv project config
â””â”€â”€ uv.lock                 # Dependency lockfile
```

---

## ğŸš€ Getting Started

### 1. Clone the repository

```bash
git clone https://github.com/yourusername/hsmw-tutor.git
cd hsmw-tutor
```

### 2. Install uv

```bash
curl -LsSf https://astral.sh/uv/install.sh | sh
```

### 3. Install dependencies

```bash
uv sync
```

### 4. Run

```bash
uv run streamlit run app.py
```

Open [http://localhost:8501](http://localhost:8501) in your browser.


---

## ğŸ“– Usage

1. **Upload a PDF** â€” Use the sidebar to upload your lecture notes or slides
2. **Click "Ingest PDF"** â€” The system will chunk and embed the document
3. **Ask questions** â€” Type your question in the chat box
4. **Get grounded answers** â€” The agent retrieves relevant passages and answers based only on your lecture materials

---

## âš™ï¸ Configuration

All application settings are in `config.py`:

| Setting | Default | Description |
|---------|---------|-------------|
| `LLM_MODEL` | `llama3.2` | LLM model name on Ollama server |
| `EMBEDDING_MODEL` | `nomic-embed-text` | Embedding model name |
| `CHUNK_SIZE` | `1000` | Characters per chunk |
| `CHUNK_OVERLAP` | `200` | Overlap between chunks |
| `TOP_K` | `5` | Number of chunks to retrieve |
| `CHROMA_PERSIST_DIR` | `./chroma_db` | ChromaDB storage directory |
| `COLLECTION_NAME` | `hsmw_lectures` | ChromaDB collection name |

Remote server credentials are managed via `sicim/config.gin` (excluded from git).

---

## ğŸ”’ Security

- The `sicim/config.gin` file containing API credentials is **gitignored** and should never be committed
- All data is processed locally â€” PDFs are not sent to any external service except the HSMW Ollama server for embedding and generation

---

## ğŸ“¦ Dependencies

```
streamlit
langchain
langchain-community
langchain-ollama
langchain-text-splitters
langgraph
chromadb
pymupdf
gin-config
ollama
```

---

## ğŸ« About

Built for **Hochschule Mittweida (HSMW)** as a student Q&A tool for lecture materials.  
A fully local and open source.
